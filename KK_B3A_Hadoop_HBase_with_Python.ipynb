{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "KK B3A Hadoop HBase with Python",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Praxis-QR/BDSN/blob/main/KK_B3A_Hadoop_HBase_with_Python.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XafE9O3pAmkC"
      },
      "source": [
        "![alt text](https://4.bp.blogspot.com/-gbL5nZDkpFQ/XScFYwoTEII/AAAAAAAAAGY/CcVb_HDLwvs2Brv5T4vSsUcz7O4r2Q79ACK4BGAYYCw/s1600/kk3-header00-beta.png)<br>\n",
        "\n",
        "\n",
        "<hr>\n",
        "\n",
        "[Prithwis Mukerjee](http://www.linkedin.com/in/prithwis)<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GyYTQEpb1htS"
      },
      "source": [
        "#Hadoop \n",
        "Install and Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_r0IOmlc0-Dt"
      },
      "source": [
        "# The default JVM available at /usr/lib/jvm/java-11-openjdk-amd64/  works for Hadoop\n",
        "# But gives errors with Hive https://stackoverflow.com/questions/54037773/hive-exception-class-jdk-internal-loader-classloadersappclassloader-cannot\n",
        "# Hence this JVM needs to be installed\n",
        "!apt-get update > /dev/null\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NWspfH6A1a4P",
        "outputId": "f0e2e213-6400-4fd8-9f13-09ba1a136e3b"
      },
      "source": [
        "# Download the latest version of Hadoop\n",
        "!wget https://downloads.apache.org/hadoop/common/hadoop-3.3.0/hadoop-3.3.0.tar.gz\n",
        "# Unzip it\n",
        "# the tar command with the -x flag to extract, -z to uncompress, -v for verbose output, and -f to specify that we’re extracting from a file\n",
        "!tar -xzf hadoop-3.3.0.tar.gz\n",
        "#copy  hadoop file to user/local\n",
        "!mv  hadoop-3.3.0/ /usr/local/"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-11-26 03:52:20--  https://downloads.apache.org/hadoop/common/hadoop-3.3.0/hadoop-3.3.0.tar.gz\n",
            "Resolving downloads.apache.org (downloads.apache.org)... 88.99.95.219, 135.181.214.104, 2a01:4f9:3a:2c57::2, ...\n",
            "Connecting to downloads.apache.org (downloads.apache.org)|88.99.95.219|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 500749234 (478M) [application/x-gzip]\n",
            "Saving to: ‘hadoop-3.3.0.tar.gz’\n",
            "\n",
            "hadoop-3.3.0.tar.gz 100%[===================>] 477.55M  25.2MB/s    in 20s     \n",
            "\n",
            "2021-11-26 03:52:40 (23.9 MB/s) - ‘hadoop-3.3.0.tar.gz’ saved [500749234/500749234]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "24QjQ22V1swJ"
      },
      "source": [
        "#To find the default Java path\n",
        "#!readlink -f /usr/bin/java | sed \"s:bin/java::\"\n",
        "#!ls /usr/lib/jvm/"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ugibq3m1CbgC"
      },
      "source": [
        "## Set Hadoop Environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1j7WFh5k18E1"
      },
      "source": [
        "#To set java path, go to /usr/local/hadoop-3.3.0/etc/hadoop/hadoop-env.sh then\n",
        "#. . . export JAVA_HOME=/usr/lib/jvm/java-11-openjdk-amd64/ . . .\n",
        "#we have used a simpler alternative route using os.environ - it works\n",
        "\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"   # default is changed\n",
        "#os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64/\"\n",
        "os.environ[\"HADOOP_HOME\"] = \"/usr/local/hadoop-3.3.0/\""
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DevjcjSF2ltL"
      },
      "source": [
        "# Get the value of current_path\n",
        "#!echo $PATH\n",
        "#cPath = os.getenv('PATH')\n",
        "#print(cPath)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NaaMpfVP2p3m"
      },
      "source": [
        "# Add Hadoop BIN to PATH\n",
        "# current_path taken from last command\n",
        "#current_path = '/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/tools/node/bin:/tools/google-cloud-sdk/bin:/opt/bin'\n",
        "current_path = os.getenv('PATH')\n",
        "new_path = current_path+':/usr/local/hadoop-3.3.0/bin/'\n",
        "os.environ[\"PATH\"] = new_path"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZD34gT3y2u-D"
      },
      "source": [
        "# Testing Hadoop with PI generating sample program, should calculate value of pi = 3.14157500000000000000\n",
        "# pi example\n",
        "#Uncomment the following line if  you want to test Hadoop with pi example\n",
        "#!hadoop jar /usr/local/hadoop-3.3.0/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.3.0.jar pi 16 100000"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zHwLU0Uo3tLo"
      },
      "source": [
        "#Install HBase"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bODP1xaM3vEB",
        "outputId": "961884a5-ef03-4412-92c0-2691e318edb5"
      },
      "source": [
        "# Get the latest HBase download site from here https://www.apache.org/dyn/closer.lua/hbase/\n",
        "#!wget https://mirrors.estointernet.in/apache/hbase/2.4.5/hbase-2.4.5-bin.tar.gz\n",
        "!wget https://mirrors.estointernet.in/apache/hbase/2.4.8/hbase-2.4.8-bin.tar.gz\n",
        "#!tar xzf hbase-2.4.5-bin.tar.gz\n",
        "!tar xzf hbase-2.4.8-bin.tar.gz"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-11-26 03:57:27--  https://mirrors.estointernet.in/apache/hbase/2.4.8/hbase-2.4.8-bin.tar.gz\n",
            "Resolving mirrors.estointernet.in (mirrors.estointernet.in)... 43.255.166.254, 2403:8940:3:1::f\n",
            "Connecting to mirrors.estointernet.in (mirrors.estointernet.in)|43.255.166.254|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 283436391 (270M) [application/octet-stream]\n",
            "Saving to: ‘hbase-2.4.8-bin.tar.gz’\n",
            "\n",
            "hbase-2.4.8-bin.tar 100%[===================>] 270.31M  11.7MB/s    in 24s     \n",
            "\n",
            "2021-11-26 03:57:52 (11.2 MB/s) - ‘hbase-2.4.8-bin.tar.gz’ saved [283436391/283436391]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kaMtyNOVCiMS"
      },
      "source": [
        "## Set HBase Environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p4dc0K7h4f-y",
        "outputId": "3dafe5c5-0598-46ac-bf0e-f5c2892d0b17"
      },
      "source": [
        "#os.environ[\"HIVE_HOME\"] = \"/content/apache-hive-3.1.2-bin\"\n",
        "#!echo $HIVE_HOME\n",
        "#os.environ[\"HBASE_HOME\"] = \"/content/hbase-2.4.5/\"\n",
        "os.environ[\"HBASE_HOME\"] = \"/content/hbase-2.4.8/\"\n",
        "!echo $HBASE_HOME"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/hbase-2.4.8/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DqXZ_kF65VXK",
        "outputId": "9a59e696-6b39-407d-cb8c-7ca6848f7d69"
      },
      "source": [
        "# current_path taken from command in previous cell\n",
        "#current_path = '/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/tools/node/bin:/tools/google-cloud-sdk/bin:/opt/bin:/usr/local/hadoop-3.3.0/bin/'\n",
        "#new_path = current_path+':/content/hbase-2.4.5/bin'\n",
        "current_path = os.getenv('PATH')\n",
        "new_path = current_path+':/content/hbase-2.4.8/bin'\n",
        "os.environ[\"PATH\"] = new_path\n",
        "!echo $PATH"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/tools/node/bin:/tools/google-cloud-sdk/bin:/opt/bin:/usr/local/hadoop-3.3.0/bin/:/content/hbase-2.4.8/bin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZrS6BL5k51Bl",
        "outputId": "d22ab9b4-abc1-452a-c8b4-6bf3c28f884b"
      },
      "source": [
        "!echo $JAVA_HOME\n",
        "!echo $HADOOP_HOME\n",
        "!echo $HBASE_HOME"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/lib/jvm/java-8-openjdk-amd64\n",
            "/usr/local/hadoop-3.3.0/\n",
            "/content/hbase-2.4.8/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9kDmgFfh6a12"
      },
      "source": [
        "# the file hbase-site.xml may need to be updated ...\n",
        "# however the default file works well in the simple stand-alone HBase mode\n",
        "# so no need to touch it\n",
        "#!cat $HBASE_HOME/conf/hbase-site.xml"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BWn-DJ1PDbXd"
      },
      "source": [
        "## Some Clean UP\n",
        "Otherwise we get ugly warnings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bKG7t8sQDj2t",
        "outputId": "2d201972-548e-4a2c-ef83-e5e9419bcf50"
      },
      "source": [
        "# locate multiple instances of slf4j ...\n",
        "!ls $HADOOP_HOME/share/hadoop/common/lib/*slf4j*\n",
        "!ls $HBASE_HOME/lib/*slf4j*"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/hadoop-3.3.0//share/hadoop/common/lib/jul-to-slf4j-1.7.25.jar\n",
            "/usr/local/hadoop-3.3.0//share/hadoop/common/lib/slf4j-api-1.7.25.jar\n",
            "/usr/local/hadoop-3.3.0//share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar\n",
            "/content/hbase-2.4.8//lib/jcl-over-slf4j-1.7.30.jar\n",
            "/content/hbase-2.4.8//lib/jul-to-slf4j-1.7.30.jar\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6OaOkjD5EOr0"
      },
      "source": [
        "# remove the Hadoop logger out of the path\n",
        "# without this you will get ugly warnings every time\n",
        "!mv /usr/local/hadoop-3.3.0//share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar ."
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uA03iA4XFN_E"
      },
      "source": [
        "## Start HBase server"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GMQHzlCO7MDC",
        "outputId": "e2ec6cc6-6e58-42f6-8df0-1cd2b3ff02b2"
      },
      "source": [
        "!start-hbase.sh\n",
        "!jps"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running master, logging to /content/hbase-2.4.8//logs/hbase--master-1d6676a61ef6.out\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gd6mdgPSFSvB"
      },
      "source": [
        "# Run Hbase Shell"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "42DJQfpY7oqe"
      },
      "source": [
        "# you can enter hbase shell commands at the prompt. Double click on the prompt to open up a input box\n",
        "#!hbase shell "
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qhuHJF4lH6f6"
      },
      "source": [
        "shell commands  <br>\n",
        "https://www.tutorialspoint.com/hbase/hbase_shell.htm <br>\n",
        "https://www.guru99.com/hbase-shell-general-commands.html <br>\n",
        "better way of passing shell commands are given here"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cQdbisL2GQtE",
        "outputId": "af78ee07-9443-4b44-a4b0-24a3bf581a2d"
      },
      "source": [
        "!echo 'status' | hbase shell -n\n",
        "#!echo \"status 'detail'\" | hbase shell -n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 active master, 0 backup masters, 1 servers, 0 dead, 2.0000 average load\n",
            "Took 0.8825 seconds                                                             \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NYhR2DpgIbnU",
        "outputId": "b6a91f75-ed62-43c9-e3e6-5c2d5e63ab04"
      },
      "source": [
        "!echo \"whoami\" | hbase shell -n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root (auth:SIMPLE)\n",
            "    groups: root\n",
            "Took 0.0236 seconds                                                             \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EztkGD3HPYhb"
      },
      "source": [
        "#Bulk Data Load\n",
        "https://people.apache.org/~stack/site/bulk-loads.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v3z4W7zYzbEP",
        "outputId": "f3e22dc7-4119-4aeb-aa02-d62bcc7e4ba8"
      },
      "source": [
        "#Data as CSV file\n",
        "#!gdown https://drive.google.com/uc?id=1B6szzHNG7BCToKOktRiGUfFblrp1f_GC  # cars2.csv\n",
        "!wget https://raw.githubusercontent.com/Praxis-QR/BDSN/main/Documents/cars2.csv # cars2.csv"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-11-26 04:26:06--  https://raw.githubusercontent.com/Praxis-QR/BDSN/main/Documents/cars2.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 52 [text/plain]\n",
            "Saving to: ‘cars2.csv’\n",
            "\n",
            "\rcars2.csv             0%[                    ]       0  --.-KB/s               \rcars2.csv           100%[===================>]      52  --.-KB/s    in 0s      \n",
            "\n",
            "2021-11-26 04:26:06 (2.01 MB/s) - ‘cars2.csv’ saved [52/52]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rBJ063HuoDhA",
        "outputId": "4518a30d-73aa-46c6-fa90-c1f4ad69bfc9"
      },
      "source": [
        "# see the data\n",
        "!cat cars2.csv"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ford,Ecosport,2019\n",
            "Hyundai,i20,2015\n",
            "Maruti,Omni,2007"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EkEIeHtHkc3L",
        "outputId": "e4942e84-f860-4632-ec4c-87160bb8dc1c"
      },
      "source": [
        "!echo \"disable 'cars2'\" | hbase shell -n\n",
        "!echo \"drop 'cars2'\" | hbase shell -n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Took 0.8227 seconds                                                             ERROR ArgumentError: Table cars2 does not exist.\n",
            "Took 0.6701 seconds                                                             ERROR ArgumentError: Table cars2 does not exist.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rOlmaKHFewdi",
        "outputId": "bd487eb8-6666-441e-eb6d-1cd0f701ba5f"
      },
      "source": [
        "#create 'sensor','temp','vibration','pressure'\n",
        "!echo \"create 'cars2', 'make','model','year'\" | hbase shell -n"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created table cars2\n",
            "Took 1.3007 seconds                                                             \n",
            "Hbase::Table - cars2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hg002j_6fKQx",
        "outputId": "925ccd05-4038-434b-f8be-e6086205727a"
      },
      "source": [
        "!echo \"list\" | hbase shell -n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TABLE                                                                           \n",
            "cars2                                                                           \n",
            "1 row(s)\n",
            "Took 0.8146 seconds                                                             \n",
            "cars2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L0xLDl6_iHBA",
        "outputId": "ed4e16df-8b92-443d-b36e-d6a7ee4072c2"
      },
      "source": [
        "!cat cars2.csv"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ford,Ecosport,2019\n",
            "Hyundai,i20,2015\n",
            "Maruti,Omni,2007"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EYhznehYfZiC",
        "outputId": "57151a3f-8c9c-4a6a-fa64-385c43482e7e"
      },
      "source": [
        "# input file has to be moved from regular file system to HDFS file system\n",
        "!hdfs dfs -copyFromLocal cars2.csv /tmp"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SLF4J: Failed to load class \"org.slf4j.impl.StaticLoggerBinder\".\n",
            "SLF4J: Defaulting to no-operation (NOP) logger implementation\n",
            "SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder for further details.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CF5loP6EfxuW",
        "outputId": "c2e812b9-c147-4edf-874c-16b88d716a53"
      },
      "source": [
        "# https://community.cloudera.com/t5/Community-Articles/Import-CSV-data-into-HBase-using-importtsv/ta-p/244842\n",
        "#hbase org.apache.hadoop.hbase.mapreduce.ImportTsv -Dimporttsv.separator=,  -Dimporttsv.columns=\"HBASE_ROW_KEY,id,temp:in,temp:out,vibration,pressure:in,pressure:out\" sensor hdfs://sandbox.hortonworks.com:/tmp/hbase.csv\n",
        "!hbase org.apache.hadoop.hbase.mapreduce.ImportTsv -Dimporttsv.separator=','  -Dimporttsv.columns=\"HBASE_ROW_KEY,make,model,year\" cars2 /tmp/cars2.csv"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2021-11-26 04:27:11,846 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x367ffa75] zookeeper.ZooKeeper: Client environment:zookeeper.version=3.5.7-f0fdd52973d373ffd9c86b81d99842dc2c7f660e, built on 02/10/2020 11:30 GMT\n",
            "2021-11-26 04:27:11,847 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x367ffa75] zookeeper.ZooKeeper: Client environment:host.name=1d6676a61ef6\n",
            "2021-11-26 04:27:11,847 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x367ffa75] zookeeper.ZooKeeper: Client environment:java.version=1.8.0_292\n",
            "2021-11-26 04:27:11,847 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x367ffa75] zookeeper.ZooKeeper: Client environment:java.vendor=Private Build\n",
            "2021-11-26 04:27:11,847 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x367ffa75] zookeeper.ZooKeeper: Client environment:java.home=/usr/lib/jvm/java-8-openjdk-amd64/jre\n",
            "2021-11-26 04:27:11,847 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x367ffa75] zookeeper.ZooKeeper: sr/local/hadoop-3.3.0//share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.3.0.jar:/usr/local/hadoop-3.3.0//share/hadoop/yarn/hadoop-yarn-services-core-3.3.0.jar:/usr/local/hadoop-3.3.0//share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.3.0.jar:/usr/local/hadoop-3.3.0//share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.3.0.jar:/usr/local/hadoop-3.3.0//share/hadoop/yarn/hadoop-yarn-server-tests-3.3.0.jar:/usr/local/hadoop-3.3.0//share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.3.0.jar:/usr/local/hadoop-3.3.0//share/hadoop/yarn/hadoop-yarn-applications-mawo-core-3.3.0.jar:/usr/local/hadoop-3.3.0//share/hadoop/yarn/hadoop-yarn-common-3.3.0.jar:/usr/local/hadoop-3.3.0//share/hadoop/yarn/hadoop-yarn-services-api-3.3.0.jar:/usr/local/hadoop-3.3.0//share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.3.0.jar:/usr/local/hadoop-3.3.0//share/hadoop/yarn/hadoop-yarn-api-3.3.0.jar:/content/hbase-2.4.8//lib/client-facing-thirdparty/slf4j-log4j12-1.7.30.jar\n",
            "2021-11-26 04:27:11,847 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x367ffa75] zookeeper.ZooKeeper: Client environment:java.library.path=/usr/local/hadoop-3.3.0//lib/native\n",
            "2021-11-26 04:27:11,847 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x367ffa75] zookeeper.ZooKeeper: Client environment:java.io.tmpdir=/tmp\n",
            "2021-11-26 04:27:11,847 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x367ffa75] zookeeper.ZooKeeper: Client environment:java.compiler=<NA>\n",
            "2021-11-26 04:27:11,848 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x367ffa75] zookeeper.ZooKeeper: Client environment:os.name=Linux\n",
            "2021-11-26 04:27:11,848 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x367ffa75] zookeeper.ZooKeeper: Client environment:os.arch=amd64\n",
            "2021-11-26 04:27:11,848 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x367ffa75] zookeeper.ZooKeeper: Client environment:os.version=5.4.104+\n",
            "2021-11-26 04:27:11,848 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x367ffa75] zookeeper.ZooKeeper: Client environment:user.name=root\n",
            "2021-11-26 04:27:11,848 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x367ffa75] zookeeper.ZooKeeper: Client environment:user.home=/root\n",
            "2021-11-26 04:27:11,848 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x367ffa75] zookeeper.ZooKeeper: Client environment:user.dir=/content\n",
            "2021-11-26 04:27:11,848 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x367ffa75] zookeeper.ZooKeeper: Client environment:os.memory.free=178MB\n",
            "2021-11-26 04:27:11,848 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x367ffa75] zookeeper.ZooKeeper: Client environment:os.memory.max=3231MB\n",
            "2021-11-26 04:27:11,848 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x367ffa75] zookeeper.ZooKeeper: Client environment:os.memory.total=197MB\n",
            "2021-11-26 04:27:11,853 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x367ffa75] zookeeper.ZooKeeper: Initiating client connection, connectString=127.0.0.1:2181 sessionTimeout=90000 watcher=org.apache.hadoop.hbase.zookeeper.ReadOnlyZKClient$$Lambda$15/2135017043@9e3b131\n",
            "2021-11-26 04:27:11,861 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x367ffa75] common.X509Util: Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation\n",
            "2021-11-26 04:27:11,870 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x367ffa75] zookeeper.ClientCnxnSocket: jute.maxbuffer value is 4194304 Bytes\n",
            "2021-11-26 04:27:11,880 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x367ffa75] zookeeper.ClientCnxn: zookeeper.request.timeout value is 0. feature enabled=\n",
            "2021-11-26 04:27:11,895 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x367ffa75-SendThread(127.0.0.1:2181)] zookeeper.ClientCnxn: Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)\n",
            "2021-11-26 04:27:11,903 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x367ffa75-SendThread(127.0.0.1:2181)] zookeeper.ClientCnxn: Socket connection established, initiating session, client: /127.0.0.1:53060, server: localhost/127.0.0.1:2181\n",
            "2021-11-26 04:27:11,919 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x367ffa75-SendThread(127.0.0.1:2181)] zookeeper.ClientCnxn: Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x100000d52ac000a, negotiated timeout = 40000\n",
            "2021-11-26 04:27:13,451 INFO  [main] Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id\n",
            "2021-11-26 04:27:13,452 INFO  [main] jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=\n",
            "2021-11-26 04:27:13,549 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x367ffa75] zookeeper.ZooKeeper: Session: 0x100000d52ac000a closed\n",
            "2021-11-26 04:27:13,549 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x367ffa75-EventThread] zookeeper.ClientCnxn: EventThread shut down for session: 0x100000d52ac000a\n",
            "2021-11-26 04:27:13,563 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x470a696f] zookeeper.ZooKeeper: Initiating client connection, connectString=127.0.0.1:2181 sessionTimeout=90000 watcher=org.apache.hadoop.hbase.zookeeper.ReadOnlyZKClient$$Lambda$15/2135017043@9e3b131\n",
            "2021-11-26 04:27:13,563 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x470a696f] zookeeper.ClientCnxnSocket: jute.maxbuffer value is 4194304 Bytes\n",
            "2021-11-26 04:27:13,563 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x470a696f] zookeeper.ClientCnxn: zookeeper.request.timeout value is 0. feature enabled=\n",
            "2021-11-26 04:27:13,575 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x470a696f-SendThread(127.0.0.1:2181)] zookeeper.ClientCnxn: Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)\n",
            "2021-11-26 04:27:13,575 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x470a696f-SendThread(127.0.0.1:2181)] zookeeper.ClientCnxn: Socket connection established, initiating session, client: /127.0.0.1:53066, server: localhost/127.0.0.1:2181\n",
            "2021-11-26 04:27:13,579 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x470a696f-SendThread(127.0.0.1:2181)] zookeeper.ClientCnxn: Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x100000d52ac000b, negotiated timeout = 40000\n",
            "2021-11-26 04:27:13,728 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x470a696f] zookeeper.ZooKeeper: Session: 0x100000d52ac000b closed\n",
            "2021-11-26 04:27:13,728 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x470a696f-EventThread] zookeeper.ClientCnxn: EventThread shut down for session: 0x100000d52ac000b\n",
            "2021-11-26 04:27:13,772 INFO  [main] input.FileInputFormat: Total input files to process : 1\n",
            "2021-11-26 04:27:13,799 INFO  [main] mapreduce.JobSubmitter: number of splits:1\n",
            "2021-11-26 04:27:13,995 INFO  [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local2008904251_0001\n",
            "2021-11-26 04:27:14,296 INFO  [main] mapred.LocalDistributedCacheManager: Creating symlink: /tmp/hadoop-root/mapred/local/1637900834120/libjars <- /content/libjars/*\n",
            "2021-11-26 04:27:14,304 WARN  [main] fs.FileUtil: Command 'ln -s /tmp/hadoop-root/mapred/local/1637900834120/libjars /content/libjars/*' failed 1 with: ln: failed to create symbolic link '/content/libjars/*': No such file or directory\n",
            "\n",
            "2021-11-26 04:27:14,304 WARN  [main] mapred.LocalDistributedCacheManager: Failed to create symlink: /tmp/hadoop-root/mapred/local/1637900834120/libjars <- /content/libjars/*\n",
            "2021-11-26 04:27:14,304 INFO  [main] mapred.LocalDistributedCacheManager: Localized file:/tmp/hadoop-root/mapred/staging/root2008904251/.staging/job_local2008904251_0001/libjars as file:/tmp/hadoop-root/mapred/local/1637900834120/libjars\n",
            "2021-11-26 04:27:14,429 INFO  [main] mapreduce.Job: The url to track the job: http://localhost:8080/\n",
            "2021-11-26 04:27:14,429 INFO  [main] mapreduce.Job: Running job: job_local2008904251_0001\n",
            "2021-11-26 04:27:14,432 INFO  [Thread-7] mapred.LocalJobRunner: OutputCommitter set in config null\n",
            "2021-11-26 04:27:14,462 INFO  [Thread-7] mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.hbase.mapreduce.TableOutputCommitter\n",
            "2021-11-26 04:27:14,494 INFO  [Thread-7] mapred.LocalJobRunner: Waiting for map tasks\n",
            "2021-11-26 04:27:14,494 INFO  [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local2008904251_0001_m_000000_0\n",
            "2021-11-26 04:27:14,593 INFO  [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
            "2021-11-26 04:27:14,607 INFO  [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: file:/tmp/cars2.csv:0+52\n",
            "2021-11-26 04:27:14,622 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x29389605] zookeeper.ZooKeeper: Initiating client connection, connectString=127.0.0.1:2181 sessionTimeout=90000 watcher=org.apache.hadoop.hbase.zookeeper.ReadOnlyZKClient$$Lambda$15/2135017043@9e3b131\n",
            "2021-11-26 04:27:14,622 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x29389605] zookeeper.ClientCnxnSocket: jute.maxbuffer value is 4194304 Bytes\n",
            "2021-11-26 04:27:14,622 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x29389605] zookeeper.ClientCnxn: zookeeper.request.timeout value is 0. feature enabled=\n",
            "2021-11-26 04:27:14,623 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x29389605-SendThread(127.0.0.1:2181)] zookeeper.ClientCnxn: Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)\n",
            "2021-11-26 04:27:14,623 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x29389605-SendThread(127.0.0.1:2181)] zookeeper.ClientCnxn: Socket connection established, initiating session, client: /127.0.0.1:53074, server: localhost/127.0.0.1:2181\n",
            "2021-11-26 04:27:14,627 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x29389605-SendThread(127.0.0.1:2181)] zookeeper.ClientCnxn: Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x100000d52ac000c, negotiated timeout = 40000\n",
            "2021-11-26 04:27:14,633 INFO  [LocalJobRunner Map Task Executor #0] mapreduce.TableOutputFormat: Created table instance for cars2\n",
            "2021-11-26 04:27:14,669 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x67ef28c8] zookeeper.ZooKeeper: Initiating client connection, connectString=127.0.0.1:2181 sessionTimeout=90000 watcher=org.apache.hadoop.hbase.zookeeper.ReadOnlyZKClient$$Lambda$15/2135017043@9e3b131\n",
            "2021-11-26 04:27:14,669 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x67ef28c8] zookeeper.ClientCnxnSocket: jute.maxbuffer value is 4194304 Bytes\n",
            "2021-11-26 04:27:14,670 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x67ef28c8] zookeeper.ClientCnxn: zookeeper.request.timeout value is 0. feature enabled=\n",
            "2021-11-26 04:27:14,671 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x67ef28c8-SendThread(127.0.0.1:2181)] zookeeper.ClientCnxn: Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)\n",
            "2021-11-26 04:27:14,672 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x67ef28c8-SendThread(127.0.0.1:2181)] zookeeper.ClientCnxn: Socket connection established, initiating session, client: /127.0.0.1:53076, server: localhost/127.0.0.1:2181\n",
            "2021-11-26 04:27:14,676 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x67ef28c8-SendThread(127.0.0.1:2181)] zookeeper.ClientCnxn: Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x100000d52ac000d, negotiated timeout = 40000\n",
            "2021-11-26 04:27:14,758 INFO  [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: \n",
            "2021-11-26 04:27:14,845 INFO  [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local2008904251_0001_m_000000_0 is done. And is in the process of committing\n",
            "2021-11-26 04:27:14,855 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x67ef28c8] zookeeper.ZooKeeper: Session: 0x100000d52ac000d closed\n",
            "2021-11-26 04:27:14,855 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x67ef28c8-EventThread] zookeeper.ClientCnxn: EventThread shut down for session: 0x100000d52ac000d\n",
            "2021-11-26 04:27:14,870 INFO  [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: map\n",
            "2021-11-26 04:27:14,870 INFO  [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local2008904251_0001_m_000000_0' done.\n",
            "2021-11-26 04:27:14,877 INFO  [LocalJobRunner Map Task Executor #0] mapred.Task: Final Counters for attempt_local2008904251_0001_m_000000_0: Counters: 19\n",
            "\tFile System Counters\n",
            "\t\tFILE: Number of bytes read=431079\n",
            "\t\tFILE: Number of bytes written=1003840\n",
            "\t\tFILE: Number of read operations=0\n",
            "\t\tFILE: Number of large read operations=0\n",
            "\t\tFILE: Number of write operations=0\n",
            "\tMap-Reduce Framework\n",
            "\t\tMap input records=3\n",
            "\t\tMap output records=3\n",
            "\t\tInput split bytes=84\n",
            "\t\tSpilled Records=0\n",
            "\t\tFailed Shuffles=0\n",
            "\t\tMerged Map outputs=0\n",
            "\t\tGC time elapsed (ms)=0\n",
            "\t\tCPU time spent (ms)=330\n",
            "\t\tPhysical memory (bytes) snapshot=273596416\n",
            "\t\tVirtual memory (bytes) snapshot=5152206848\n",
            "\t\tTotal committed heap usage (bytes)=206831616\n",
            "\tImportTsv\n",
            "\t\tBad Lines=0\n",
            "\tFile Input Format Counters \n",
            "\t\tBytes Read=72\n",
            "\tFile Output Format Counters \n",
            "\t\tBytes Written=0\n",
            "2021-11-26 04:27:14,877 INFO  [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local2008904251_0001_m_000000_0\n",
            "2021-11-26 04:27:14,877 INFO  [Thread-7] mapred.LocalJobRunner: map task executor complete.\n",
            "2021-11-26 04:27:14,953 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x29389605] zookeeper.ZooKeeper: Session: 0x100000d52ac000c closed\n",
            "2021-11-26 04:27:14,953 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x29389605-EventThread] zookeeper.ClientCnxn: EventThread shut down for session: 0x100000d52ac000c\n",
            "2021-11-26 04:27:15,435 INFO  [main] mapreduce.Job: Job job_local2008904251_0001 running in uber mode : false\n",
            "2021-11-26 04:27:15,437 INFO  [main] mapreduce.Job:  map 100% reduce 0%\n",
            "2021-11-26 04:27:15,439 INFO  [main] mapreduce.Job: Job job_local2008904251_0001 completed successfully\n",
            "2021-11-26 04:27:15,445 INFO  [main] mapreduce.Job: Counters: 19\n",
            "\tFile System Counters\n",
            "\t\tFILE: Number of bytes read=431079\n",
            "\t\tFILE: Number of bytes written=1003840\n",
            "\t\tFILE: Number of read operations=0\n",
            "\t\tFILE: Number of large read operations=0\n",
            "\t\tFILE: Number of write operations=0\n",
            "\tMap-Reduce Framework\n",
            "\t\tMap input records=3\n",
            "\t\tMap output records=3\n",
            "\t\tInput split bytes=84\n",
            "\t\tSpilled Records=0\n",
            "\t\tFailed Shuffles=0\n",
            "\t\tMerged Map outputs=0\n",
            "\t\tGC time elapsed (ms)=0\n",
            "\t\tCPU time spent (ms)=330\n",
            "\t\tPhysical memory (bytes) snapshot=273596416\n",
            "\t\tVirtual memory (bytes) snapshot=5152206848\n",
            "\t\tTotal committed heap usage (bytes)=206831616\n",
            "\tImportTsv\n",
            "\t\tBad Lines=0\n",
            "\tFile Input Format Counters \n",
            "\t\tBytes Read=72\n",
            "\tFile Output Format Counters \n",
            "\t\tBytes Written=0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CSs-MATjgw6p",
        "outputId": "c3f42dc4-9e52-4aeb-e9d8-61944544e169"
      },
      "source": [
        "!echo \"scan 'cars2'\" | hbase shell -n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROW                   COLUMN+CELL                                               \n",
            " Ford                 column=make:, timestamp=2021-11-25T01:50:15.068, value=Eco\n",
            "                      sport                                                     \n",
            " Ford                 column=model:, timestamp=2021-11-25T01:50:15.068, value=20\n",
            "                      19                                                        \n",
            " Hyundai              column=make:, timestamp=2021-11-25T01:50:15.068, value=i20\n",
            " Hyundai              column=model:, timestamp=2021-11-25T01:50:15.068, value=20\n",
            "                      15                                                        \n",
            " Maruti               column=make:, timestamp=2021-11-25T01:50:15.068, value=Omn\n",
            "                      i                                                         \n",
            " Maruti               column=model:, timestamp=2021-11-25T01:50:15.068, value=20\n",
            "                      07                                                        \n",
            "3 row(s)\n",
            "Took 0.6660 seconds                                                             \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_RMwSSDZd6T9"
      },
      "source": [
        "#Install HappyBase / Thrift <br>\n",
        "https://happybase.readthedocs.io/en/latest/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7qOwqJlQfQLc",
        "outputId": "f7ea7944-eda6-48c4-eb3b-70caac15b1fb"
      },
      "source": [
        "!stop-hbase.sh"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "stopping hbase..............\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QLfCN8jpZsZH",
        "outputId": "76a47007-3611-4c49-dd03-0d292690bb48"
      },
      "source": [
        "!pip install happybase"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting happybase\n",
            "  Downloading happybase-1.2.0.tar.gz (40 kB)\n",
            "\u001b[K     |████████████████████████████████| 40 kB 3.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from happybase) (1.15.0)\n",
            "Collecting thriftpy2>=0.4\n",
            "  Downloading thriftpy2-0.4.14.tar.gz (361 kB)\n",
            "\u001b[K     |████████████████████████████████| 361 kB 6.5 MB/s \n",
            "\u001b[?25hCollecting ply<4.0,>=3.4\n",
            "  Downloading ply-3.11-py2.py3-none-any.whl (49 kB)\n",
            "\u001b[K     |████████████████████████████████| 49 kB 4.9 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: happybase, thriftpy2\n",
            "  Building wheel for happybase (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for happybase: filename=happybase-1.2.0-py2.py3-none-any.whl size=26622 sha256=ba6d17bbf715c637a323dafdbc92ee4e05a6ccb85849c09d8520aff95d72ecc9\n",
            "  Stored in directory: /root/.cache/pip/wheels/66/63/48/437f79a3724a4a529830f87d766a7d34228d623e845de2c321\n",
            "  Building wheel for thriftpy2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for thriftpy2: filename=thriftpy2-0.4.14-cp37-cp37m-linux_x86_64.whl size=940435 sha256=0ebb93ada9432b878045c8b42720cf2522954a3216d7fcfcae5793bc261003e0\n",
            "  Stored in directory: /root/.cache/pip/wheels/2a/f5/49/9c0d851aa64b58db72883cf9393cc824d536bdf13f5c83cff4\n",
            "Successfully built happybase thriftpy2\n",
            "Installing collected packages: ply, thriftpy2, happybase\n",
            "Successfully installed happybase-1.2.0 ply-3.11 thriftpy2-0.4.14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J-Wt2asZZb3m"
      },
      "source": [
        "import happybase\n",
        "#https://happybase.readthedocs.io/en/latest/"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A-OVMxNEaWOq",
        "outputId": "9589414d-7b0e-4288-e93d-2fbe2136c436"
      },
      "source": [
        "#!ls hbase-2.4.8/bin\n",
        "#!hbase-2.4.8/bin/hbase-daemon.sh start thrift\n",
        "!hbase-daemon.sh start thrift"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running thrift, logging to /content/hbase-2.4.8//logs/hbase--thrift-1d6676a61ef6.out\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_UHyIyGFf0yl",
        "outputId": "bf5a2e55-66e2-4350-d07a-b3dc2a3cb5e7"
      },
      "source": [
        "!start-hbase.sh\n",
        "!jps"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running master, logging to /content/hbase-2.4.8//logs/hbase--master-1d6676a61ef6.out\n",
            "3124 Jps\n",
            "2600 ThriftServer\n",
            "2970 HMaster\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C4yg79ueMhYZ"
      },
      "source": [
        "#Working with HBase"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BwmPaWqwZ9GV"
      },
      "source": [
        "#connection = happybase.Connection('localhost',9090, transport='framed',protocol='compact')\n",
        "kxn = happybase.Connection('localhost',9090,autoconnect=False)"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aFjctMtoeCcW",
        "outputId": "c0316ca4-b191-4037-9643-b4b4083fdb05"
      },
      "source": [
        "kxn.open()\n",
        "kxn.tables()"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[b'Dept', b'Emp', b'EmpDept', b'cars2']"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2zvAuebzbXj6"
      },
      "source": [
        "##Create Dept Table, Insert Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AiUqgnVCMcl3"
      },
      "source": [
        "kxn.open()\n",
        "#Drop Table\n",
        "#kxn.disable_table('Dept')\n",
        "#kxn.delete_table('Dept')\n",
        "#Create Table\n",
        "kxn.create_table(\n",
        "    'Dept',\n",
        "    {'DeptID': dict(max_versions=10),\n",
        "     'DeptName': dict(max_versions=1, block_cache_enabled=False),\n",
        "     'ManagerID': dict(),  # use defaults\n",
        "     'Location': dict(),  # use defaults\n",
        "    }\n",
        ")\n",
        "kxn.close()"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SsULtvF6Nfcx"
      },
      "source": [
        "kxn.open()\n",
        "tDept = kxn.table('Dept')\n",
        "kxn.close()"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I1jju96MNoCf"
      },
      "source": [
        "kxn.open()\n",
        "tDept.put('10',{'DeptName:': 'Corporate', 'ManagerID:': '123456','Location:':'Calcutta'})\n",
        "kxn.close()"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cP5nd0nIOTxf",
        "outputId": "5d0cd8a9-96c5-413c-ff31-c225ba0022e0"
      },
      "source": [
        "kxn.open()\n",
        "for key, data in tDept.scan():\n",
        "    print(key, data)\n",
        "kxn.close()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "b'10' {b'DeptName:': b'Corporate', b'Location:': b'Calcutta', b'ManagerID:': b'123456'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y0Y9zgCJOywZ"
      },
      "source": [
        "kxn.open()\n",
        "b = tDept.batch()\n",
        "b.put(b'20', { b'DeptName:': b'Sales', b'ManagerID:': b'234567', b'Location:': b'Calcutta'})\n",
        "b.put(b'30', { b'DeptName:': b'Accounts', b'ManagerID:': b'567234', b'Location:': b'Calcutta'})\n",
        "b.put(b'40', { b'DeptName:': b'Production', b'ManagerID:': b'345876', b'Location:': b'Bombay'})\n",
        "b.send()\n",
        "kxn.close()"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nn9puFvNSQ0I",
        "outputId": "10f76b3b-78c9-4d6b-9d37-dfc3c56846af"
      },
      "source": [
        "kxn.open()\n",
        "#tDept = kxn.table('Dept')\n",
        "for key, data in tDept.scan():\n",
        "    print(key, data)\n",
        "kxn.close()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "b'10' {b'DeptName:': b'Corporate', b'Location:': b'Calcutta', b'ManagerID:': b'123456'}\n",
            "b'20' {b'DeptName:': b'Sales', b'Location:': b'Calcutta', b'ManagerID:': b'234567'}\n",
            "b'30' {b'DeptName:': b'Accounts', b'Location:': b'Calcutta', b'ManagerID:': b'567234'}\n",
            "b'40' {b'DeptName:': b'Production', b'Location:': b'Bombay', b'ManagerID:': b'345876'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6sjTzUYObi7W"
      },
      "source": [
        "##Create Emp Table, LOAD data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y8GbQWvRcTwu"
      },
      "source": [
        "kxn.open()\n",
        "#Drop Table\n",
        "#kxn.disable_table('Emp')\n",
        "#kxn.delete_table('Emp')\n",
        "#Create Table\n",
        "kxn.create_table(\n",
        "    'Emp',\n",
        "    {'EmpID': dict(max_versions=10),\n",
        "     'LastName': dict(),  # use defaults\n",
        "     'FirstName': dict(),  # use defaults\n",
        "     'Role': dict(),  # use defaults\n",
        "     'DoJ': dict(),  # use defaults\n",
        "     'Salary': dict(),  # use defaults\n",
        "     'Comm': dict(),  # use defaults\n",
        "     'DeptID': dict(),  # use defaults\n",
        "    }\n",
        ")\n",
        "kxn.close()"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M9XDyx1HQxBL",
        "outputId": "3d363652-1e73-45b6-d25a-eb37a2e504d2"
      },
      "source": [
        "kxn.open()\n",
        "kxn.tables()"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[b'Dept', b'Emp']"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jZbsNgyBd-aN",
        "outputId": "c6cb3c7b-0acc-4a20-c7d6-f0fddc43b92d"
      },
      "source": [
        "# input file has to be moved from regular file system to HDFS file system\n",
        "!hdfs dfs -copyFromLocal Employee.csv /tmp"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SLF4J: Failed to load class \"org.slf4j.impl.StaticLoggerBinder\".\n",
            "SLF4J: Defaulting to no-operation (NOP) logger implementation\n",
            "SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder for further details.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pFRp3yateTCS",
        "outputId": "2cf3cd9f-9b7b-4ce0-b5d7-93b470f9a0dd"
      },
      "source": [
        "# https://community.cloudera.com/t5/Community-Articles/Import-CSV-data-into-HBase-using-importtsv/ta-p/244842\n",
        "#hbase org.apache.hadoop.hbase.mapreduce.ImportTsv -Dimporttsv.separator=,  -Dimporttsv.columns=\"HBASE_ROW_KEY,id,temp:in,temp:out,vibration,pressure:in,pressure:out\" sensor hdfs://sandbox.hortonworks.com:/tmp/hbase.csv\n",
        "!hbase org.apache.hadoop.hbase.mapreduce.ImportTsv -Dimporttsv.separator=','  -Dimporttsv.columns=\"HBASE_ROW_KEY,LastName:,FirstName:,Role:,DoJ:,Salary:,Comm:,DeptID:\" Emp /tmp/Employee.csv"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2021-11-26 04:28:04,084 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x367ffa75] zookeeper.ZooKeeper: Client environment:zookeeper.version=3.5.7-f0fdd52973d373ffd9c86b81d99842dc2c7f660e, built on 02/10/2020 11:30 GMT\n",
            "2021-11-26 04:28:04,085 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x367ffa75] zookeeper.ZooKeeper: Client environment:host.name=1d6676a61ef6\n",
            "2021-11-26 04:28:04,085 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x367ffa75] zookeeper.ZooKeeper: Client environment:java.version=1.8.0_292\n",
            "2021-11-26 04:28:04,085 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x367ffa75] zookeeper.ZooKeeper: Client environment:java.vendor=Private Build\n",
            "2021-11-26 04:28:04,085 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x367ffa75] zookeeper.ZooKeeper: Client environment:java.home=/usr/lib/jvm/java-8-openjdk-amd64/jre\n",
            "2021-11-26 04:28:04,085 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x367ffa75] zookeeper.ZooKeeper: sr/local/hadoop-3.3.0//share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.3.0.jar:/usr/local/hadoop-3.3.0//share/hadoop/yarn/hadoop-yarn-services-core-3.3.0.jar:/usr/local/hadoop-3.3.0//share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.3.0.jar:/usr/local/hadoop-3.3.0//share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.3.0.jar:/usr/local/hadoop-3.3.0//share/hadoop/yarn/hadoop-yarn-server-tests-3.3.0.jar:/usr/local/hadoop-3.3.0//share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.3.0.jar:/usr/local/hadoop-3.3.0//share/hadoop/yarn/hadoop-yarn-applications-mawo-core-3.3.0.jar:/usr/local/hadoop-3.3.0//share/hadoop/yarn/hadoop-yarn-common-3.3.0.jar:/usr/local/hadoop-3.3.0//share/hadoop/yarn/hadoop-yarn-services-api-3.3.0.jar:/usr/local/hadoop-3.3.0//share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.3.0.jar:/usr/local/hadoop-3.3.0//share/hadoop/yarn/hadoop-yarn-api-3.3.0.jar:/content/hbase-2.4.8//lib/client-facing-thirdparty/slf4j-log4j12-1.7.30.jar\n",
            "2021-11-26 04:28:04,085 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x367ffa75] zookeeper.ZooKeeper: Client environment:java.library.path=/usr/local/hadoop-3.3.0//lib/native\n",
            "2021-11-26 04:28:04,085 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x367ffa75] zookeeper.ZooKeeper: Client environment:java.io.tmpdir=/tmp\n",
            "2021-11-26 04:28:04,085 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x367ffa75] zookeeper.ZooKeeper: Client environment:java.compiler=<NA>\n",
            "2021-11-26 04:28:04,086 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x367ffa75] zookeeper.ZooKeeper: Client environment:os.name=Linux\n",
            "2021-11-26 04:28:04,086 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x367ffa75] zookeeper.ZooKeeper: Client environment:os.arch=amd64\n",
            "2021-11-26 04:28:04,086 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x367ffa75] zookeeper.ZooKeeper: Client environment:os.version=5.4.104+\n",
            "2021-11-26 04:28:04,086 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x367ffa75] zookeeper.ZooKeeper: Client environment:user.name=root\n",
            "2021-11-26 04:28:04,086 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x367ffa75] zookeeper.ZooKeeper: Client environment:user.home=/root\n",
            "2021-11-26 04:28:04,086 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x367ffa75] zookeeper.ZooKeeper: Client environment:user.dir=/content\n",
            "2021-11-26 04:28:04,086 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x367ffa75] zookeeper.ZooKeeper: Client environment:os.memory.free=178MB\n",
            "2021-11-26 04:28:04,086 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x367ffa75] zookeeper.ZooKeeper: Client environment:os.memory.max=3231MB\n",
            "2021-11-26 04:28:04,086 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x367ffa75] zookeeper.ZooKeeper: Client environment:os.memory.total=197MB\n",
            "2021-11-26 04:28:04,091 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x367ffa75] zookeeper.ZooKeeper: Initiating client connection, connectString=127.0.0.1:2181 sessionTimeout=90000 watcher=org.apache.hadoop.hbase.zookeeper.ReadOnlyZKClient$$Lambda$15/968062886@414e7d7f\n",
            "2021-11-26 04:28:04,097 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x367ffa75] common.X509Util: Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation\n",
            "2021-11-26 04:28:04,104 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x367ffa75] zookeeper.ClientCnxnSocket: jute.maxbuffer value is 4194304 Bytes\n",
            "2021-11-26 04:28:04,112 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x367ffa75] zookeeper.ClientCnxn: zookeeper.request.timeout value is 0. feature enabled=\n",
            "2021-11-26 04:28:04,128 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x367ffa75-SendThread(127.0.0.1:2181)] zookeeper.ClientCnxn: Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)\n",
            "2021-11-26 04:28:04,133 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x367ffa75-SendThread(127.0.0.1:2181)] zookeeper.ClientCnxn: Socket connection established, initiating session, client: /127.0.0.1:53184, server: localhost/127.0.0.1:2181\n",
            "2021-11-26 04:28:04,142 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x367ffa75-SendThread(127.0.0.1:2181)] zookeeper.ClientCnxn: Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x100000d52ac000e, negotiated timeout = 40000\n",
            "2021-11-26 04:28:05,739 INFO  [main] Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id\n",
            "2021-11-26 04:28:05,740 INFO  [main] jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=\n",
            "2021-11-26 04:28:05,822 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x367ffa75] zookeeper.ZooKeeper: Session: 0x100000d52ac000e closed\n",
            "2021-11-26 04:28:05,822 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x367ffa75-EventThread] zookeeper.ClientCnxn: EventThread shut down for session: 0x100000d52ac000e\n",
            "2021-11-26 04:28:05,829 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x470a696f] zookeeper.ZooKeeper: Initiating client connection, connectString=127.0.0.1:2181 sessionTimeout=90000 watcher=org.apache.hadoop.hbase.zookeeper.ReadOnlyZKClient$$Lambda$15/968062886@414e7d7f\n",
            "2021-11-26 04:28:05,829 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x470a696f] zookeeper.ClientCnxnSocket: jute.maxbuffer value is 4194304 Bytes\n",
            "2021-11-26 04:28:05,829 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x470a696f] zookeeper.ClientCnxn: zookeeper.request.timeout value is 0. feature enabled=\n",
            "2021-11-26 04:28:05,830 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x470a696f-SendThread(127.0.0.1:2181)] zookeeper.ClientCnxn: Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)\n",
            "2021-11-26 04:28:05,831 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x470a696f-SendThread(127.0.0.1:2181)] zookeeper.ClientCnxn: Socket connection established, initiating session, client: /127.0.0.1:53198, server: localhost/127.0.0.1:2181\n",
            "2021-11-26 04:28:05,835 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x470a696f-SendThread(127.0.0.1:2181)] zookeeper.ClientCnxn: Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x100000d52ac000f, negotiated timeout = 40000\n",
            "2021-11-26 04:28:05,971 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x470a696f] zookeeper.ZooKeeper: Session: 0x100000d52ac000f closed\n",
            "2021-11-26 04:28:05,972 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x470a696f-EventThread] zookeeper.ClientCnxn: EventThread shut down for session: 0x100000d52ac000f\n",
            "2021-11-26 04:28:06,031 INFO  [main] input.FileInputFormat: Total input files to process : 1\n",
            "2021-11-26 04:28:06,091 INFO  [main] mapreduce.JobSubmitter: number of splits:1\n",
            "2021-11-26 04:28:06,396 INFO  [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local1192535900_0001\n",
            "2021-11-26 04:28:06,835 INFO  [main] mapred.LocalDistributedCacheManager: Creating symlink: /tmp/hadoop-root/mapred/local/1637900886605/libjars <- /content/libjars/*\n",
            "2021-11-26 04:28:06,844 WARN  [main] fs.FileUtil: Command 'ln -s /tmp/hadoop-root/mapred/local/1637900886605/libjars /content/libjars/*' failed 1 with: ln: failed to create symbolic link '/content/libjars/*': No such file or directory\n",
            "\n",
            "2021-11-26 04:28:06,844 WARN  [main] mapred.LocalDistributedCacheManager: Failed to create symlink: /tmp/hadoop-root/mapred/local/1637900886605/libjars <- /content/libjars/*\n",
            "2021-11-26 04:28:06,844 INFO  [main] mapred.LocalDistributedCacheManager: Localized file:/tmp/hadoop-root/mapred/staging/root1192535900/.staging/job_local1192535900_0001/libjars as file:/tmp/hadoop-root/mapred/local/1637900886605/libjars\n",
            "2021-11-26 04:28:06,936 INFO  [main] mapreduce.Job: The url to track the job: http://localhost:8080/\n",
            "2021-11-26 04:28:06,936 INFO  [main] mapreduce.Job: Running job: job_local1192535900_0001\n",
            "2021-11-26 04:28:06,943 INFO  [Thread-7] mapred.LocalJobRunner: OutputCommitter set in config null\n",
            "2021-11-26 04:28:06,974 INFO  [Thread-7] mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.hbase.mapreduce.TableOutputCommitter\n",
            "2021-11-26 04:28:07,010 INFO  [Thread-7] mapred.LocalJobRunner: Waiting for map tasks\n",
            "2021-11-26 04:28:07,011 INFO  [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local1192535900_0001_m_000000_0\n",
            "2021-11-26 04:28:07,084 INFO  [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
            "2021-11-26 04:28:07,100 INFO  [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: file:/tmp/Employee.csv:0+672\n",
            "2021-11-26 04:28:07,118 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x33e32c0e] zookeeper.ZooKeeper: Initiating client connection, connectString=127.0.0.1:2181 sessionTimeout=90000 watcher=org.apache.hadoop.hbase.zookeeper.ReadOnlyZKClient$$Lambda$15/968062886@414e7d7f\n",
            "2021-11-26 04:28:07,118 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x33e32c0e] zookeeper.ClientCnxnSocket: jute.maxbuffer value is 4194304 Bytes\n",
            "2021-11-26 04:28:07,119 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x33e32c0e] zookeeper.ClientCnxn: zookeeper.request.timeout value is 0. feature enabled=\n",
            "2021-11-26 04:28:07,121 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x33e32c0e-SendThread(127.0.0.1:2181)] zookeeper.ClientCnxn: Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)\n",
            "2021-11-26 04:28:07,123 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x33e32c0e-SendThread(127.0.0.1:2181)] zookeeper.ClientCnxn: Socket connection established, initiating session, client: /127.0.0.1:53206, server: localhost/127.0.0.1:2181\n",
            "2021-11-26 04:28:07,127 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x33e32c0e-SendThread(127.0.0.1:2181)] zookeeper.ClientCnxn: Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x100000d52ac0010, negotiated timeout = 40000\n",
            "2021-11-26 04:28:07,133 INFO  [LocalJobRunner Map Task Executor #0] mapreduce.TableOutputFormat: Created table instance for Emp\n",
            "2021-11-26 04:28:07,164 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x042bbb0c] zookeeper.ZooKeeper: Initiating client connection, connectString=127.0.0.1:2181 sessionTimeout=90000 watcher=org.apache.hadoop.hbase.zookeeper.ReadOnlyZKClient$$Lambda$15/968062886@414e7d7f\n",
            "2021-11-26 04:28:07,164 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x042bbb0c] zookeeper.ClientCnxnSocket: jute.maxbuffer value is 4194304 Bytes\n",
            "2021-11-26 04:28:07,165 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x042bbb0c] zookeeper.ClientCnxn: zookeeper.request.timeout value is 0. feature enabled=\n",
            "2021-11-26 04:28:07,166 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x042bbb0c-SendThread(127.0.0.1:2181)] zookeeper.ClientCnxn: Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)\n",
            "2021-11-26 04:28:07,168 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x042bbb0c-SendThread(127.0.0.1:2181)] zookeeper.ClientCnxn: Socket connection established, initiating session, client: /127.0.0.1:53208, server: localhost/127.0.0.1:2181\n",
            "2021-11-26 04:28:07,172 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x042bbb0c-SendThread(127.0.0.1:2181)] zookeeper.ClientCnxn: Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x100000d52ac0011, negotiated timeout = 40000\n",
            "2021-11-26 04:28:07,271 INFO  [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: \n",
            "2021-11-26 04:28:07,360 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x042bbb0c] zookeeper.ZooKeeper: Session: 0x100000d52ac0011 closed\n",
            "2021-11-26 04:28:07,361 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x042bbb0c-EventThread] zookeeper.ClientCnxn: EventThread shut down for session: 0x100000d52ac0011\n",
            "2021-11-26 04:28:07,460 INFO  [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local1192535900_0001_m_000000_0 is done. And is in the process of committing\n",
            "2021-11-26 04:28:07,480 INFO  [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: map\n",
            "2021-11-26 04:28:07,480 INFO  [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local1192535900_0001_m_000000_0' done.\n",
            "2021-11-26 04:28:07,490 INFO  [LocalJobRunner Map Task Executor #0] mapred.Task: Final Counters for attempt_local1192535900_0001_m_000000_0: Counters: 19\n",
            "\tFile System Counters\n",
            "\t\tFILE: Number of bytes read=431708\n",
            "\t\tFILE: Number of bytes written=1003919\n",
            "\t\tFILE: Number of read operations=0\n",
            "\t\tFILE: Number of large read operations=0\n",
            "\t\tFILE: Number of write operations=0\n",
            "\tMap-Reduce Framework\n",
            "\t\tMap input records=12\n",
            "\t\tMap output records=12\n",
            "\t\tInput split bytes=87\n",
            "\t\tSpilled Records=0\n",
            "\t\tFailed Shuffles=0\n",
            "\t\tMerged Map outputs=0\n",
            "\t\tGC time elapsed (ms)=0\n",
            "\t\tCPU time spent (ms)=390\n",
            "\t\tPhysical memory (bytes) snapshot=267354112\n",
            "\t\tVirtual memory (bytes) snapshot=5143314432\n",
            "\t\tTotal committed heap usage (bytes)=206831616\n",
            "\tImportTsv\n",
            "\t\tBad Lines=0\n",
            "\tFile Input Format Counters \n",
            "\t\tBytes Read=696\n",
            "\tFile Output Format Counters \n",
            "\t\tBytes Written=0\n",
            "2021-11-26 04:28:07,491 INFO  [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local1192535900_0001_m_000000_0\n",
            "2021-11-26 04:28:07,491 INFO  [Thread-7] mapred.LocalJobRunner: map task executor complete.\n",
            "2021-11-26 04:28:07,567 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x33e32c0e] zookeeper.ZooKeeper: Session: 0x100000d52ac0010 closed\n",
            "2021-11-26 04:28:07,567 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x33e32c0e-EventThread] zookeeper.ClientCnxn: EventThread shut down for session: 0x100000d52ac0010\n",
            "2021-11-26 04:28:07,941 INFO  [main] mapreduce.Job: Job job_local1192535900_0001 running in uber mode : false\n",
            "2021-11-26 04:28:07,942 INFO  [main] mapreduce.Job:  map 100% reduce 0%\n",
            "2021-11-26 04:28:07,944 INFO  [main] mapreduce.Job: Job job_local1192535900_0001 completed successfully\n",
            "2021-11-26 04:28:07,949 INFO  [main] mapreduce.Job: Counters: 19\n",
            "\tFile System Counters\n",
            "\t\tFILE: Number of bytes read=431708\n",
            "\t\tFILE: Number of bytes written=1003919\n",
            "\t\tFILE: Number of read operations=0\n",
            "\t\tFILE: Number of large read operations=0\n",
            "\t\tFILE: Number of write operations=0\n",
            "\tMap-Reduce Framework\n",
            "\t\tMap input records=12\n",
            "\t\tMap output records=12\n",
            "\t\tInput split bytes=87\n",
            "\t\tSpilled Records=0\n",
            "\t\tFailed Shuffles=0\n",
            "\t\tMerged Map outputs=0\n",
            "\t\tGC time elapsed (ms)=0\n",
            "\t\tCPU time spent (ms)=390\n",
            "\t\tPhysical memory (bytes) snapshot=267354112\n",
            "\t\tVirtual memory (bytes) snapshot=5143314432\n",
            "\t\tTotal committed heap usage (bytes)=206831616\n",
            "\tImportTsv\n",
            "\t\tBad Lines=0\n",
            "\tFile Input Format Counters \n",
            "\t\tBytes Read=696\n",
            "\tFile Output Format Counters \n",
            "\t\tBytes Written=0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jxvMPuZ8gOW5"
      },
      "source": [
        "kxn.open()\n",
        "tEmp = kxn.table('Emp')\n",
        "kxn.close()"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uonqOE2AgXeq",
        "outputId": "4c5f0683-bf5e-4697-b5a3-dd56b4c0f395"
      },
      "source": [
        "kxn.open()\n",
        "#tDept = kxn.table('Dept')\n",
        "for key, data in tEmp.scan():\n",
        "    print(key, data)\n",
        "kxn.close()"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "b'123980' {b'Comm:': b'0.02', b'DeptID:': b'40', b'DoJ:': b'2004-10-09', b'FirstName:': b'Mahender', b'LastName:': b'Dhoni', b'Role:': b'Clerk', b'Salary:': b'9000'}\n",
            "b'223112' {b'Comm:': b'0.04', b'DeptID:': b'30', b'DoJ:': b'2001-11-19', b'FirstName:': b'Sania', b'LastName:': b'Mirza', b'Role:': b'Cus_Rep', b'Salary:': b'25000'}\n",
            "b'239456' {b'Comm:': b'0.07', b'DeptID:': b'20', b'DoJ:': b'2004-01-03', b'FirstName:': b'Shahrukh', b'LastName:': b'Khan', b'Role:': b'Manager', b'Salary:': b'30000'}\n",
            "b'299034' {b'Comm:': b'0.11', b'DeptID:': b'10', b'DoJ:': b'2002-10-10', b'FirstName:': b'Rekha', b'LastName:': b'Ganesan', b'Role:': b'Director', b'Salary:': b'60000'}\n",
            "b'349870' {b'Comm:': b'0.06', b'DeptID:': b'40', b'DoJ:': b'2005-05-04', b'FirstName:': b'Rani', b'LastName:': b'Mukherjee', b'Role:': b'Manager', b'Salary:': b'25000'}\n",
            "b'546223' {b'Comm:': b'0.09', b'DeptID:': b'10', b'DoJ:': b'2005-12-04', b'FirstName:': b'Narayan', b'LastName:': b'Karthikeyan', b'Role:': b'Secretary', b'Salary:': b'40000'}\n",
            "b'742866' {b'Comm:': b'0.1', b'DeptID:': b'10', b'DoJ:': b'2003-03-10', b'FirstName:': b'Amitabh', b'LastName:': b'Bacchan', b'Role:': b'Executive', b'Salary:': b'50000'}\n",
            "b'822134' {b'Comm:': b'0.08', b'DeptID:': b'30', b'DoJ:': b'2000-06-04', b'FirstName:': b'Rahul', b'LastName:': b'Dravid', b'Role:': b'Sr Manager', b'Salary:': b'40000'}\n",
            "b'865477' {b'Comm:': b'0.02', b'DeptID:': b'20', b'DoJ:': b'2002-04-04', b'FirstName:': b'Madhuri', b'LastName:': b'Dikshit', b'Role:': b'Clerk', b'Salary:': b'10000'}\n",
            "b'897889' {b'Comm:': b'0.05', b'DeptID:': b'20', b'DoJ:': b'2005-01-02', b'FirstName:': b'Virender', b'LastName:': b'Sehwag', b'Role:': b'Cus_Rep', b'Salary:': b'15000'}\n",
            "b'989007' {b'Comm:': b'0.03', b'DeptID:': b'40', b'DoJ:': b'2002-01-01', b'FirstName:': b'Sourav', b'LastName:': b'Ganguly', b'Role:': b'Cus_Rep', b'Salary:': b'20000'}\n",
            "b'997445' {b'Comm:': b'0.02', b'DeptID:': b'30', b'DoJ:': b'2001-07-01', b'FirstName:': b'Jagmohan', b'LastName:': b'Dalmia', b'Role:': b'Clerk', b'Salary:': b'12000'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TS__XdMYjLzd"
      },
      "source": [
        "## Creating, INSERTing Denormalised EmpDept Table"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HQRpLsmfjbgp"
      },
      "source": [
        "kxn.open()\n",
        "#Drop Table\n",
        "#kxn.disable_table('EmpDept')\n",
        "#kxn.delete_table('EmpDept')\n",
        "#Create Table\n",
        "kxn.create_table(\n",
        "    'EmpDept',\n",
        "    {'EmpID': dict(max_versions=10),\n",
        "     'Emp': dict(),  # use defaults\n",
        "     'Dept': dict(),  # use defaults\n",
        "    }\n",
        ")\n",
        "kxn.close()"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NI6Zk4bKqMas",
        "outputId": "63760e89-2f75-4cec-affa-621beb84e27f"
      },
      "source": [
        "kxn.open()\n",
        "kxn.tables()"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[b'Dept', b'Emp', b'EmpDept', b'cars2']"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "duGwwpF1n5IG"
      },
      "source": [
        "kxn.open()\n",
        "tEmpDept = kxn.table('EmpDept')\n",
        "b = tEmpDept.batch()\n",
        "b.put(b'742866', { b'Emp:FirstName': b'Amitabh', b'Dept:DeptName': b'Corporate', b'Dept:Location': b'Calcutta'})\n",
        "b.put(b'349870', { b'Emp:LastName': b'Mukheree', b'Dept:ManagerID': b'567234', b'Dept:Location:': b'Bombay'})\n",
        "b.send()\n",
        "kxn.close()"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AzxFRXp7rS87",
        "outputId": "aaff09d8-ccb0-44ce-aaf5-0665e6f33f12"
      },
      "source": [
        "kxn.open()\n",
        "#tDept = kxn.table('Dept')\n",
        "for key, data in tEmpDept.scan():\n",
        "    print(key, data)\n",
        "kxn.close()"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "b'349870' {b'Dept:Location:': b'Bombay', b'Dept:ManagerID': b'567234', b'Emp:LastName': b'Mukheree'}\n",
            "b'742866' {b'Dept:DeptName': b'Corporate', b'Dept:Location': b'Calcutta', b'Emp:FirstName': b'Amitabh'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YWZKpJ_LtMnQ"
      },
      "source": [
        "##Creating and LOADing denormalised tables EmpDept2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "giAKNFnMtJ-b"
      },
      "source": [
        "kxn.open()\n",
        "#Drop Table\n",
        "kxn.disable_table('EmpDept2')\n",
        "kxn.delete_table('EmpDept2')\n",
        "#Create Table\n",
        "kxn.create_table(\n",
        "    'EmpDept2',\n",
        "    {'EmpID': dict(max_versions=10),\n",
        "     'Emp': dict(),  # use defaults\n",
        "     'Dept': dict(),  # use defaults\n",
        "    }\n",
        ")\n",
        "kxn.close()"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s2WwCA4euf-i",
        "outputId": "ab345fb0-1cb9-4498-e36e-3e24749411e7"
      },
      "source": [
        "kxn.open()\n",
        "kxn.tables()"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[b'Dept', b'Emp', b'EmpDept', b'EmpDept2', b'cars2']"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vvItjBLuu7oM",
        "outputId": "82ce72c1-c250-4fa7-de0b-d2d41e5bb8c9"
      },
      "source": [
        "# input file has to be moved from regular file system to HDFS file system\n",
        "!hdfs dfs -copyFromLocal EmployeeDept2.txt /tmp"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SLF4J: Failed to load class \"org.slf4j.impl.StaticLoggerBinder\".\n",
            "SLF4J: Defaulting to no-operation (NOP) logger implementation\n",
            "SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder for further details.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j_VFWQZJvXqn",
        "outputId": "c752b5c5-c129-4202-ff87-1d559460d64d"
      },
      "source": [
        "# https://community.cloudera.com/t5/Community-Articles/Import-CSV-data-into-HBase-using-importtsv/ta-p/244842\n",
        "#hbase org.apache.hadoop.hbase.mapreduce.ImportTsv -Dimporttsv.separator=,  -Dimporttsv.columns=\"HBASE_ROW_KEY,id,temp:in,temp:out,vibration,pressure:in,pressure:out\" sensor hdfs://sandbox.hortonworks.com:/tmp/hbase.csv\n",
        "!hbase org.apache.hadoop.hbase.mapreduce.ImportTsv -Dimporttsv.separator=','  -Dimporttsv.columns=\"HBASE_ROW_KEY,Emp:LastName,Emp:FirstName,Emp:Role,Emp:DoJ,Emp:Salary,Emp:Comm,Dept:DeptID,Dept:DeptName,Dept:ManagerID,Dept:Location\" EmpDept2 /tmp/EmployeeDept2.txt"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2021-11-26 05:54:47,947 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x367ffa75] zookeeper.ZooKeeper: Client environment:zookeeper.version=3.5.7-f0fdd52973d373ffd9c86b81d99842dc2c7f660e, built on 02/10/2020 11:30 GMT\n",
            "2021-11-26 05:54:47,947 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x367ffa75] zookeeper.ZooKeeper: Client environment:host.name=1d6676a61ef6\n",
            "2021-11-26 05:54:47,947 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x367ffa75] zookeeper.ZooKeeper: Client environment:java.version=1.8.0_292\n",
            "2021-11-26 05:54:47,947 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x367ffa75] zookeeper.ZooKeeper: Client environment:java.vendor=Private Build\n",
            "2021-11-26 05:54:47,948 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x367ffa75] zookeeper.ZooKeeper: Client environment:java.home=/usr/lib/jvm/java-8-openjdk-amd64/jre\n",
            "2021-11-26 05:54:47,948 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x367ffa75] zookeeper.ZooKeeper: sr/local/hadoop-3.3.0//share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.3.0.jar:/usr/local/hadoop-3.3.0//share/hadoop/yarn/hadoop-yarn-services-core-3.3.0.jar:/usr/local/hadoop-3.3.0//share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.3.0.jar:/usr/local/hadoop-3.3.0//share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.3.0.jar:/usr/local/hadoop-3.3.0//share/hadoop/yarn/hadoop-yarn-server-tests-3.3.0.jar:/usr/local/hadoop-3.3.0//share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.3.0.jar:/usr/local/hadoop-3.3.0//share/hadoop/yarn/hadoop-yarn-applications-mawo-core-3.3.0.jar:/usr/local/hadoop-3.3.0//share/hadoop/yarn/hadoop-yarn-common-3.3.0.jar:/usr/local/hadoop-3.3.0//share/hadoop/yarn/hadoop-yarn-services-api-3.3.0.jar:/usr/local/hadoop-3.3.0//share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.3.0.jar:/usr/local/hadoop-3.3.0//share/hadoop/yarn/hadoop-yarn-api-3.3.0.jar:/content/hbase-2.4.8//lib/client-facing-thirdparty/slf4j-log4j12-1.7.30.jar\n",
            "2021-11-26 05:54:47,948 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x367ffa75] zookeeper.ZooKeeper: Client environment:java.library.path=/usr/local/hadoop-3.3.0//lib/native\n",
            "2021-11-26 05:54:47,948 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x367ffa75] zookeeper.ZooKeeper: Client environment:java.io.tmpdir=/tmp\n",
            "2021-11-26 05:54:47,948 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x367ffa75] zookeeper.ZooKeeper: Client environment:java.compiler=<NA>\n",
            "2021-11-26 05:54:47,948 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x367ffa75] zookeeper.ZooKeeper: Client environment:os.name=Linux\n",
            "2021-11-26 05:54:47,948 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x367ffa75] zookeeper.ZooKeeper: Client environment:os.arch=amd64\n",
            "2021-11-26 05:54:47,948 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x367ffa75] zookeeper.ZooKeeper: Client environment:os.version=5.4.104+\n",
            "2021-11-26 05:54:47,948 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x367ffa75] zookeeper.ZooKeeper: Client environment:user.name=root\n",
            "2021-11-26 05:54:47,948 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x367ffa75] zookeeper.ZooKeeper: Client environment:user.home=/root\n",
            "2021-11-26 05:54:47,948 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x367ffa75] zookeeper.ZooKeeper: Client environment:user.dir=/content\n",
            "2021-11-26 05:54:47,948 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x367ffa75] zookeeper.ZooKeeper: Client environment:os.memory.free=178MB\n",
            "2021-11-26 05:54:47,948 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x367ffa75] zookeeper.ZooKeeper: Client environment:os.memory.max=3231MB\n",
            "2021-11-26 05:54:47,948 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x367ffa75] zookeeper.ZooKeeper: Client environment:os.memory.total=197MB\n",
            "2021-11-26 05:54:47,954 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x367ffa75] zookeeper.ZooKeeper: Initiating client connection, connectString=127.0.0.1:2181 sessionTimeout=90000 watcher=org.apache.hadoop.hbase.zookeeper.ReadOnlyZKClient$$Lambda$15/968062886@414e7d7f\n",
            "2021-11-26 05:54:47,962 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x367ffa75] common.X509Util: Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation\n",
            "2021-11-26 05:54:47,970 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x367ffa75] zookeeper.ClientCnxnSocket: jute.maxbuffer value is 4194304 Bytes\n",
            "2021-11-26 05:54:47,980 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x367ffa75] zookeeper.ClientCnxn: zookeeper.request.timeout value is 0. feature enabled=\n",
            "2021-11-26 05:54:47,992 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x367ffa75-SendThread(127.0.0.1:2181)] zookeeper.ClientCnxn: Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)\n",
            "2021-11-26 05:54:47,999 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x367ffa75-SendThread(127.0.0.1:2181)] zookeeper.ClientCnxn: Socket connection established, initiating session, client: /127.0.0.1:33668, server: localhost/127.0.0.1:2181\n",
            "2021-11-26 05:54:48,010 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x367ffa75-SendThread(127.0.0.1:2181)] zookeeper.ClientCnxn: Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x100000d52ac0020, negotiated timeout = 40000\n",
            "2021-11-26 05:54:49,497 INFO  [main] Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id\n",
            "2021-11-26 05:54:49,498 INFO  [main] jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=\n",
            "2021-11-26 05:54:49,564 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x367ffa75] zookeeper.ZooKeeper: Session: 0x100000d52ac0020 closed\n",
            "2021-11-26 05:54:49,564 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x367ffa75-EventThread] zookeeper.ClientCnxn: EventThread shut down for session: 0x100000d52ac0020\n",
            "2021-11-26 05:54:49,587 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x470a696f] zookeeper.ZooKeeper: Initiating client connection, connectString=127.0.0.1:2181 sessionTimeout=90000 watcher=org.apache.hadoop.hbase.zookeeper.ReadOnlyZKClient$$Lambda$15/968062886@414e7d7f\n",
            "2021-11-26 05:54:49,587 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x470a696f] zookeeper.ClientCnxnSocket: jute.maxbuffer value is 4194304 Bytes\n",
            "2021-11-26 05:54:49,587 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x470a696f] zookeeper.ClientCnxn: zookeeper.request.timeout value is 0. feature enabled=\n",
            "2021-11-26 05:54:49,598 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x470a696f-SendThread(127.0.0.1:2181)] zookeeper.ClientCnxn: Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)\n",
            "2021-11-26 05:54:49,599 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x470a696f-SendThread(127.0.0.1:2181)] zookeeper.ClientCnxn: Socket connection established, initiating session, client: /127.0.0.1:33674, server: localhost/127.0.0.1:2181\n",
            "2021-11-26 05:54:49,605 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x470a696f-SendThread(127.0.0.1:2181)] zookeeper.ClientCnxn: Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x100000d52ac0021, negotiated timeout = 40000\n",
            "2021-11-26 05:54:49,750 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x470a696f] zookeeper.ZooKeeper: Session: 0x100000d52ac0021 closed\n",
            "2021-11-26 05:54:49,750 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x470a696f-EventThread] zookeeper.ClientCnxn: EventThread shut down for session: 0x100000d52ac0021\n",
            "2021-11-26 05:54:49,787 INFO  [main] input.FileInputFormat: Total input files to process : 1\n",
            "2021-11-26 05:54:49,826 INFO  [main] mapreduce.JobSubmitter: number of splits:1\n",
            "2021-11-26 05:54:50,079 INFO  [main] mapreduce.JobSubmitter: Submitting tokens for job: job_local1877298790_0001\n",
            "2021-11-26 05:54:50,461 INFO  [main] mapred.LocalDistributedCacheManager: Creating symlink: /tmp/hadoop-root/mapred/local/1637906090280/libjars <- /content/libjars/*\n",
            "2021-11-26 05:54:50,469 WARN  [main] fs.FileUtil: Command 'ln -s /tmp/hadoop-root/mapred/local/1637906090280/libjars /content/libjars/*' failed 1 with: ln: failed to create symbolic link '/content/libjars/*': No such file or directory\n",
            "\n",
            "2021-11-26 05:54:50,469 WARN  [main] mapred.LocalDistributedCacheManager: Failed to create symlink: /tmp/hadoop-root/mapred/local/1637906090280/libjars <- /content/libjars/*\n",
            "2021-11-26 05:54:50,469 INFO  [main] mapred.LocalDistributedCacheManager: Localized file:/tmp/hadoop-root/mapred/staging/root1877298790/.staging/job_local1877298790_0001/libjars as file:/tmp/hadoop-root/mapred/local/1637906090280/libjars\n",
            "2021-11-26 05:54:50,561 INFO  [main] mapreduce.Job: The url to track the job: http://localhost:8080/\n",
            "2021-11-26 05:54:50,562 INFO  [main] mapreduce.Job: Running job: job_local1877298790_0001\n",
            "2021-11-26 05:54:50,568 INFO  [Thread-7] mapred.LocalJobRunner: OutputCommitter set in config null\n",
            "2021-11-26 05:54:50,598 INFO  [Thread-7] mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.hbase.mapreduce.TableOutputCommitter\n",
            "2021-11-26 05:54:50,630 INFO  [Thread-7] mapred.LocalJobRunner: Waiting for map tasks\n",
            "2021-11-26 05:54:50,631 INFO  [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local1877298790_0001_m_000000_0\n",
            "2021-11-26 05:54:50,706 INFO  [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
            "2021-11-26 05:54:50,718 INFO  [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: file:/tmp/EmployeeDept2.txt:0+966\n",
            "2021-11-26 05:54:50,730 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x246024cb] zookeeper.ZooKeeper: Initiating client connection, connectString=127.0.0.1:2181 sessionTimeout=90000 watcher=org.apache.hadoop.hbase.zookeeper.ReadOnlyZKClient$$Lambda$15/968062886@414e7d7f\n",
            "2021-11-26 05:54:50,731 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x246024cb] zookeeper.ClientCnxnSocket: jute.maxbuffer value is 4194304 Bytes\n",
            "2021-11-26 05:54:50,731 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x246024cb] zookeeper.ClientCnxn: zookeeper.request.timeout value is 0. feature enabled=\n",
            "2021-11-26 05:54:50,732 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x246024cb-SendThread(127.0.0.1:2181)] zookeeper.ClientCnxn: Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)\n",
            "2021-11-26 05:54:50,733 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x246024cb-SendThread(127.0.0.1:2181)] zookeeper.ClientCnxn: Socket connection established, initiating session, client: /127.0.0.1:33682, server: localhost/127.0.0.1:2181\n",
            "2021-11-26 05:54:50,737 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x246024cb-SendThread(127.0.0.1:2181)] zookeeper.ClientCnxn: Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x100000d52ac0022, negotiated timeout = 40000\n",
            "2021-11-26 05:54:50,743 INFO  [LocalJobRunner Map Task Executor #0] mapreduce.TableOutputFormat: Created table instance for EmpDept2\n",
            "2021-11-26 05:54:50,774 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x20d2d444] zookeeper.ZooKeeper: Initiating client connection, connectString=127.0.0.1:2181 sessionTimeout=90000 watcher=org.apache.hadoop.hbase.zookeeper.ReadOnlyZKClient$$Lambda$15/968062886@414e7d7f\n",
            "2021-11-26 05:54:50,775 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x20d2d444] zookeeper.ClientCnxnSocket: jute.maxbuffer value is 4194304 Bytes\n",
            "2021-11-26 05:54:50,776 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x20d2d444] zookeeper.ClientCnxn: zookeeper.request.timeout value is 0. feature enabled=\n",
            "2021-11-26 05:54:50,779 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x20d2d444-SendThread(127.0.0.1:2181)] zookeeper.ClientCnxn: Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)\n",
            "2021-11-26 05:54:50,780 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x20d2d444-SendThread(127.0.0.1:2181)] zookeeper.ClientCnxn: Socket connection established, initiating session, client: /127.0.0.1:33684, server: localhost/127.0.0.1:2181\n",
            "2021-11-26 05:54:50,784 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x20d2d444-SendThread(127.0.0.1:2181)] zookeeper.ClientCnxn: Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x100000d52ac0023, negotiated timeout = 40000\n",
            "2021-11-26 05:54:50,876 INFO  [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: \n",
            "2021-11-26 05:54:50,971 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x20d2d444] zookeeper.ZooKeeper: Session: 0x100000d52ac0023 closed\n",
            "2021-11-26 05:54:50,971 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x20d2d444-EventThread] zookeeper.ClientCnxn: EventThread shut down for session: 0x100000d52ac0023\n",
            "2021-11-26 05:54:50,980 INFO  [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local1877298790_0001_m_000000_0 is done. And is in the process of committing\n",
            "2021-11-26 05:54:50,999 INFO  [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: map\n",
            "2021-11-26 05:54:51,000 INFO  [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local1877298790_0001_m_000000_0' done.\n",
            "2021-11-26 05:54:51,008 INFO  [LocalJobRunner Map Task Executor #0] mapred.Task: Final Counters for attempt_local1877298790_0001_m_000000_0: Counters: 19\n",
            "\tFile System Counters\n",
            "\t\tFILE: Number of bytes read=432007\n",
            "\t\tFILE: Number of bytes written=1004084\n",
            "\t\tFILE: Number of read operations=0\n",
            "\t\tFILE: Number of large read operations=0\n",
            "\t\tFILE: Number of write operations=0\n",
            "\tMap-Reduce Framework\n",
            "\t\tMap input records=12\n",
            "\t\tMap output records=12\n",
            "\t\tInput split bytes=92\n",
            "\t\tSpilled Records=0\n",
            "\t\tFailed Shuffles=0\n",
            "\t\tMerged Map outputs=0\n",
            "\t\tGC time elapsed (ms)=0\n",
            "\t\tCPU time spent (ms)=420\n",
            "\t\tPhysical memory (bytes) snapshot=267018240\n",
            "\t\tVirtual memory (bytes) snapshot=5146271744\n",
            "\t\tTotal committed heap usage (bytes)=206831616\n",
            "\tImportTsv\n",
            "\t\tBad Lines=0\n",
            "\tFile Input Format Counters \n",
            "\t\tBytes Read=990\n",
            "\tFile Output Format Counters \n",
            "\t\tBytes Written=0\n",
            "2021-11-26 05:54:51,008 INFO  [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local1877298790_0001_m_000000_0\n",
            "2021-11-26 05:54:51,008 INFO  [Thread-7] mapred.LocalJobRunner: map task executor complete.\n",
            "2021-11-26 05:54:51,084 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x246024cb] zookeeper.ZooKeeper: Session: 0x100000d52ac0022 closed\n",
            "2021-11-26 05:54:51,084 INFO  [ReadOnlyZKClient-127.0.0.1:2181@0x246024cb-EventThread] zookeeper.ClientCnxn: EventThread shut down for session: 0x100000d52ac0022\n",
            "2021-11-26 05:54:51,567 INFO  [main] mapreduce.Job: Job job_local1877298790_0001 running in uber mode : false\n",
            "2021-11-26 05:54:51,568 INFO  [main] mapreduce.Job:  map 100% reduce 0%\n",
            "2021-11-26 05:54:51,570 INFO  [main] mapreduce.Job: Job job_local1877298790_0001 completed successfully\n",
            "2021-11-26 05:54:51,579 INFO  [main] mapreduce.Job: Counters: 19\n",
            "\tFile System Counters\n",
            "\t\tFILE: Number of bytes read=432007\n",
            "\t\tFILE: Number of bytes written=1004084\n",
            "\t\tFILE: Number of read operations=0\n",
            "\t\tFILE: Number of large read operations=0\n",
            "\t\tFILE: Number of write operations=0\n",
            "\tMap-Reduce Framework\n",
            "\t\tMap input records=12\n",
            "\t\tMap output records=12\n",
            "\t\tInput split bytes=92\n",
            "\t\tSpilled Records=0\n",
            "\t\tFailed Shuffles=0\n",
            "\t\tMerged Map outputs=0\n",
            "\t\tGC time elapsed (ms)=0\n",
            "\t\tCPU time spent (ms)=420\n",
            "\t\tPhysical memory (bytes) snapshot=267018240\n",
            "\t\tVirtual memory (bytes) snapshot=5146271744\n",
            "\t\tTotal committed heap usage (bytes)=206831616\n",
            "\tImportTsv\n",
            "\t\tBad Lines=0\n",
            "\tFile Input Format Counters \n",
            "\t\tBytes Read=990\n",
            "\tFile Output Format Counters \n",
            "\t\tBytes Written=0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-H5Zh5UwRzd"
      },
      "source": [
        "tEmpDept2 = kxn.table('EmpDept2')"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I4tQppiqwMTk",
        "outputId": "4d617d85-c078-4969-cc33-63340fb8b5b9"
      },
      "source": [
        "kxn.open()\n",
        "tEmpDept2 = kxn.table('EmpDept2')\n",
        "for key, data in tEmpDept2.scan():\n",
        "    print(key, data)\n",
        "kxn.close()"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "b'123980' {b'Dept:DeptID': b'40', b'Dept:DeptName': b'Production', b'Dept:Location': b'Bombay', b'Dept:ManagerID': b'349870', b'Emp:Comm': b'0.02', b'Emp:DoJ': b'2004-10-09', b'Emp:FirstName': b'Mahender', b'Emp:LastName': b'Dhoni', b'Emp:Role': b'Clerk', b'Emp:Salary': b'9000'}\n",
            "b'223112' {b'Dept:DeptID': b'30', b'Dept:DeptName': b'Accounts', b'Dept:Location': b'Calcutta', b'Dept:ManagerID': b'822134', b'Emp:Comm': b'0.04', b'Emp:DoJ': b'2001-11-19', b'Emp:FirstName': b'Sania', b'Emp:LastName': b'Mirza', b'Emp:Role': b'Cus_Rep', b'Emp:Salary': b'25000'}\n",
            "b'239456' {b'Dept:DeptID': b'20', b'Dept:DeptName': b'Sales', b'Dept:Location': b'Calcutta', b'Dept:ManagerID': b'239456', b'Emp:Comm': b'0.07', b'Emp:DoJ': b'2004-01-03', b'Emp:FirstName': b'Shahrukh', b'Emp:LastName': b'Khan', b'Emp:Role': b'Manager', b'Emp:Salary': b'30000'}\n",
            "b'299034' {b'Dept:DeptID': b'10', b'Dept:DeptName': b'Corporate', b'Dept:Location': b'Calcutta', b'Dept:ManagerID': b'299034', b'Emp:Comm': b'0.11', b'Emp:DoJ': b'2002-10-10', b'Emp:FirstName': b'Rekha', b'Emp:LastName': b'Ganesan', b'Emp:Role': b'Director', b'Emp:Salary': b'60000'}\n",
            "b'349870' {b'Dept:DeptID': b'40', b'Dept:DeptName': b'Production', b'Dept:Location': b'Bombay', b'Dept:ManagerID': b'349870', b'Emp:Comm': b'0.06', b'Emp:DoJ': b'2005-05-04', b'Emp:FirstName': b'Rani', b'Emp:LastName': b'Mukherjee', b'Emp:Role': b'Manager', b'Emp:Salary': b'25000'}\n",
            "b'546223' {b'Dept:DeptID': b'10', b'Dept:DeptName': b'Corporate', b'Dept:Location': b'Calcutta', b'Dept:ManagerID': b'299034', b'Emp:Comm': b'0.09', b'Emp:DoJ': b'2005-12-04', b'Emp:FirstName': b'Narayan', b'Emp:LastName': b'Karthikeyan', b'Emp:Role': b'Secretary', b'Emp:Salary': b'40000'}\n",
            "b'742866' {b'Dept:DeptID': b'10', b'Dept:DeptName': b'Corporate', b'Dept:Location': b'Calcutta', b'Dept:ManagerID': b'299034', b'Emp:Comm': b'0.1', b'Emp:DoJ': b'2003-03-10', b'Emp:FirstName': b'Amitabh', b'Emp:LastName': b'Bacchan', b'Emp:Role': b'Executive', b'Emp:Salary': b'50000'}\n",
            "b'822134' {b'Dept:DeptID': b'30', b'Dept:DeptName': b'Accounts', b'Dept:Location': b'Calcutta', b'Dept:ManagerID': b'822134', b'Emp:Comm': b'0.08', b'Emp:DoJ': b'2000-06-04', b'Emp:FirstName': b'Rahul', b'Emp:LastName': b'Dravid', b'Emp:Role': b'Sr Manager', b'Emp:Salary': b'40000'}\n",
            "b'865477' {b'Dept:DeptID': b'20', b'Dept:DeptName': b'Sales', b'Dept:Location': b'Calcutta', b'Dept:ManagerID': b'239456', b'Emp:Comm': b'0.02', b'Emp:DoJ': b'2002-04-04', b'Emp:FirstName': b'Madhuri', b'Emp:LastName': b'Dikshit', b'Emp:Role': b'Clerk', b'Emp:Salary': b'10000'}\n",
            "b'897889' {b'Dept:DeptID': b'20', b'Dept:DeptName': b'Sales', b'Dept:Location': b'Calcutta', b'Dept:ManagerID': b'239456', b'Emp:Comm': b'0.05', b'Emp:DoJ': b'2005-01-02', b'Emp:FirstName': b'Virender', b'Emp:LastName': b'Sehwag', b'Emp:Role': b'Cus_Rep', b'Emp:Salary': b'15000'}\n",
            "b'989007' {b'Dept:DeptID': b'40', b'Dept:DeptName': b'Production', b'Dept:Location': b'Bombay', b'Dept:ManagerID': b'349870', b'Emp:Comm': b'0.03', b'Emp:DoJ': b'2002-01-01', b'Emp:FirstName': b'Sourav', b'Emp:LastName': b'Ganguly', b'Emp:Role': b'Cus_Rep', b'Emp:Salary': b'20000'}\n",
            "b'997445' {b'Dept:DeptID': b'30', b'Dept:DeptName': b'Accounts', b'Dept:Location': b'Calcutta', b'Dept:ManagerID': b'822134', b'Emp:Comm': b'0.02', b'Emp:DoJ': b'2001-07-01', b'Emp:FirstName': b'Jagmohan', b'Emp:LastName': b'Dalmia', b'Emp:Role': b'Clerk', b'Emp:Salary': b'12000'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O6PP3akdlVKJ"
      },
      "source": [
        "#Stop HBase"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p28XBoitAWTL",
        "outputId": "dd7a744c-06a2-46a4-c5b2-5df654c49bf3"
      },
      "source": [
        "!stop-hbase.sh"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "stopping hbase............\n"
          ]
        }
      ]
    }
  ]
}